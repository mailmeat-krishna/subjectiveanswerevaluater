# subjectiveanswerevaluater

INTRODUCTION
The proposed system will be able to evaluate the descriptive answer to a subjective question. It will allot
the marks according to the percentage of accuracy present in the answer.
Because online tests are now based on objective questions and are becoming more and more digitized  globally, they are advantageous to users. In exam questions may even be based on subjective responses in this situation. This means that computer-based examinations, which have been shown to be (i) more accurate in awarding marks and (ii) faster than teachers correcting papers [1,11,12], will take the place of conventional pen-and-paper assessments. Traditional exams frequently included subjective answers, which were not the most accurate indicators of how well students understood the material. Since checking numerous answer sheets might get boring for examiners, which could lead to a rise in incorrect evaluations. (G., 2020)

A student's performance and abilities can be evaluated in an open-ended way using subjective questions and replies.
Naturally, there are no restrictions on the answers, and students are allowed to construct them in accordance with their perspectives and conceptual understanding. Having said that, there are still a number of crucial distinctions between subjective and objective solutions. These are longer than the objective questions, for starters. Second, writing them requires more time. Also, they require a lot more focus and neutrality from the teacher grading them due to the fact that they contain a lot more context. (M. F. Bashir, 2021)

Exams that may be subjective or in the form of multiple choice questions are used to determine a person's capability and performance. The objective examinations are simpler to automatically score. The resources and effort are reduced as a result. The main issue, however, is that most exams are still subjective in character, therefore computerized grading is for objective exams while a comparable answer for subjective exams has not yet been discovered. It is one of the most taxing duties involved in running any educational institution. The typical test procedure includes giving out examination paper to students, having them write their answers on it, having an examiner collect those sheets, and then as the final step, submitting those sheets to the authority that is in charge of the exam. (Nisarg Chakravarty, 2021)

The majority of colleges and institutions have switched to the online mode of exams during the COVID-19 pandemic's quarantine period. Though these tests consist primarily of multiple-choice questions (MCQs) or other straightforward questions that the testing system can quickly correct. The examination of questions that require more than simply a radio or checkbox click, such as lengthy subjective responses that may require manual involvement for evaluation purposes, presents a significant difficulty in education because such systems can only be utilized for objective type questions. Subjective answer evaluations are still not widely used in public cloud services like online courses. This restricts the reach of online testing and evaluation.

For using this application we have to scan the answer to a question, then the system will automatically generate the keyword using OCR technique. Based on keywords written in the answer and the keywords in the dataset, the application provides marks. (S. Bharadia, 2018)

Answer selected by the student (String1) is compared 
with the answer stored in the database( String2) 
provided by the checker. If String1= String2 then 
score=+1 or else score=0. After processing the results 
of the test into the database the results are displayed to 
the student.

Automated Answering for Subjective Examination:- This is a nice platform for answer checking. It has a feature which allows more than one possible answer to the question and provides marks for any possible answer. (Asmita Dhokrat, 2012)

Subjective answer checking is the process of evaluating and grading subjective answers, such as essays and written assignments, based on specific criteria. This process is typically performed by human teachers or instructors, but with the increasing use of technology in education, the development of automated subjective answer checkers has become a topic of interest. An AI-powered subjective answer checker can save time, reduce human error, and provide more objective grading . Traditional answer evaluation, i.e., manual checking of  answers, takes a lot of time and energy. However, objective-type questions can be evaluated using computers very efficiently, but there is no platform for checking the answers very precisely and efficiently when it comes to theoretical evaluation of answers. So invariably, there is a need for a checker to check the answers manually, which takes a lot of effort and time, and sometimes he/she must provide the feedback, which would again take a lot of effort and analysis. 

Hence, we propose a system that evaluates the assessment copies automatically according to the rubric set by the checker for every type of question (subjective and objective) and also for multiple types of copies like pdf, scanned pdf. Our system would also give feedback over every question in a sheet generated for each student.

FUTURE SCOPE OF THE PROJECT
One of the potential area of development is to improve the accuracy of the system in identifying subtle nuances in language that are important for grading subjective answers. This could involve the use of more advanced natural language processing techniques, such as deep learning and neural networks. Finally, the usability and accessibility of the system could be improved by developing a user-friendly interface that is easy to navigate and understand. This could include the integration of features that provide students with personalized feedback on their answers, as well as tools that allow teachers to monitor student progress and identify areas where additional instruction may be necessary. Currently, online subjective answer checkers are primarily used in language-based subjects such as English and languages. However, in the future, these tools could expand to other domains such as science, mathematics, and social studies.
This system is not efficient but it is less time consuming and still lacks the feature of extracting the handwritten text from the image i.e. this model checks only digital or printed text. 


